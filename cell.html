<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Praterich Voice Assistant</title>
<style>
  :root {
    --accent: #00ffff;
    --accent-glow: #00ffff66;
    --border-color: #444;
    --bg-dark: #111;
  }

  body {
    font-family: "Inter", system-ui, sans-serif;
    background: radial-gradient(circle at top, #181818, #000);
    color: white;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh;
    overflow: hidden;
    margin: 0;
    padding: 0;
    text-align: center;
  }

  .logo {
    width: 28vw;
    max-width: 160px;
    border-radius: 50%;
    border: 3px solid var(--accent);
    box-shadow: 0 0 25px var(--accent-glow);
    animation: float 4s ease-in-out infinite;
    object-fit: cover;
  }

  @keyframes float {
    0%, 100% { transform: translateY(0px); }
    50% { transform: translateY(-10px); }
  }

  h1 {
    font-weight: 500;
    font-size: 1.4rem;
    margin-top: 1.2rem;
    color: #ccc;
  }

  .mic-button {
    background: #1e1e1e;
    border: 3px solid var(--border-color);
    border-radius: 50%;
    width: 24vw;
    height: 24vw;
    max-width: 120px;
    max-height: 120px;
    margin-top: 2rem;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    transition: all 0.3s ease;
    position: relative;
  }

  .mic-button:hover, .mic-button:active {
    border-color: var(--accent);
    box-shadow: 0 0 20px var(--accent-glow);
  }

  .mic-button.active {
    animation: pulse 1.5s infinite;
    border-color: var(--accent);
    box-shadow: 0 0 25px var(--accent-glow);
  }

  @keyframes pulse {
    0% { box-shadow: 0 0 10px var(--accent-glow); }
    50% { box-shadow: 0 0 30px var(--accent-glow); }
    100% { box-shadow: 0 0 10px var(--accent-glow); }
  }

  .status {
    margin-top: 1rem;
    font-size: 1rem;
    color: #aaa;
    padding: 0 1rem;
  }

  .log {
    margin-top: 1rem;
    font-size: 0.9rem;
    max-width: 90%;
    color: #77e;
  }

  select {
    margin-top: 1.5rem;
    background: #1e1e1e;
    color: white;
    border: 1px solid var(--border-color);
    padding: 0.5rem 1rem;
    border-radius: 6px;
    font-size: 1rem;
  }

  .mic-icon {
    width: 40%;
    filter: invert(1);
  }

  @media (max-width: 600px) {
    .status { font-size: 0.9rem; }
    h1 { font-size: 1.2rem; }
  }
</style>
</head>
<body>
  <img src="https://stenoip.github.io/praterich/praterich.png" alt="Praterich Logo" class="logo">
  <h1>Praterich Voice Assistant</h1>

  <div class="mic-button" id="micButton">
    <img src="https://cdn-icons-png.flaticon.com/512/727/727245.png" alt="Microphone" class="mic-icon">
  </div>

  <div class="status" id="status">Tap the mic to start listening</div>
  <div class="log" id="log"></div>

  <select id="languageSelect">
    <option value="en-US" selected>English</option>
    <option value="es-ES">Spanish</option>
    <option value="fr-FR">French</option>
    <option value="de-DE">German</option>
    <option value="it-IT">Italian</option>
    <option value="pt-BR">Portuguese</option>
  </select>

<script>
const API_URL = "https://praterich.vercel.app/api/praterich";

const systemInstruction = `
You are Praterich, a smart and casual AI voice assistant made by Stenoip Company.
You speak naturally, conversationally, and human-like.
Use metric units only. Avoid robotic tone.
When the user switches languages, continue in that language.
`;

const customPronunciations = {
  "Praterich": "Prah-ter-rich",
  "Stenoip": "Steh-no-ip"
};

const micButton = document.getElementById("micButton");
const statusEl = document.getElementById("status");
const logEl = document.getElementById("log");
const languageSelect = document.getElementById("languageSelect");

let recognition;
let listening = false;
let currentLanguage = languageSelect.value;

// ---- SPEECH SYNTHESIS ----
function speakText(text, onEndCallback) {
  window.speechSynthesis.cancel();
  let speakable = text;
  for (const [word, pronunciation] of Object.entries(customPronunciations)) {
    const regex = new RegExp(`\\b${word}\\b`, "gi");
    speakable = speakable.replace(regex, pronunciation);
  }

  const utterance = new SpeechSynthesisUtterance(speakable);
  utterance.rate = 1.1;
  utterance.pitch = 1.0;
  utterance.lang = currentLanguage;

  utterance.onend = () => {
    if (onEndCallback) onEndCallback();
  };

  window.speechSynthesis.speak(utterance);
}

// ---- SPEECH RECOGNITION ----
function setupRecognition() {
  if (!("webkitSpeechRecognition" in window)) {
    alert("Your browser doesnâ€™t support speech recognition.");
    return;
  }
  recognition = new webkitSpeechRecognition();
  recognition.lang = currentLanguage;
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript.trim();
    logEl.textContent = `You said: "${transcript}"`;
    sendVoiceMessage(transcript);
  };

  recognition.onend = () => {
    if (listening) {
      listening = false;
      micButton.classList.remove("active");
      statusEl.textContent = "Tap the mic to talk again";
    }
  };
}
setupRecognition();

// ---- API COMMUNICATION ----
async function sendVoiceMessage(userText) {
  statusEl.textContent = "Thinking...";
  const requestBody = {
    contents: [{ role: "user", parts: [{ text: userText }] }],
    system_instruction: { parts: [{ text: systemInstruction }] },
    language: currentLanguage
  };

  try {
    const res = await fetch(API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(requestBody)
    });

    if (!res.ok) throw new Error(await res.text());
    const data = await res.json();
    const reply = data.text || "Sorry, I didn't get that.";

    // Voice only
    speakText(reply, () => startListening());

  } catch (err) {
    console.error(err);
    speakText("Sorry, there was a problem connecting to my server.");
    statusEl.textContent = "Connection error";
  }
}

// ---- CONTROL ----
function startListening() {
  if (!recognition) return;
  window.speechSynthesis.cancel();
  recognition.lang = currentLanguage;
  recognition.start();
  listening = true;
  micButton.classList.add("active");
  statusEl.textContent = `Listening (${languageSelect.options[languageSelect.selectedIndex].text})...`;
}

function stopListening() {
  if (recognition && listening) {
    recognition.stop();
    listening = false;
    micButton.classList.remove("active");
    statusEl.textContent = "Stopped listening";
  }
}

// ---- EVENT HANDLERS ----
micButton.addEventListener("click", () => {
  if (!listening) startListening();
  else stopListening();
});

languageSelect.addEventListener("change", () => {
  currentLanguage = languageSelect.value;
  setupRecognition();
  speakText(`Language switched to ${languageSelect.options[languageSelect.selectedIndex].text}.`);
});

// ---- INITIAL GREETING ----
speakText("Hello, I'm Praterich. Tap the mic to talk to me.");
</script>
</body>
</html>
